

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="#3f51b5">
  <script src="../../_static/javascripts/modernizr.js"></script>
  
  
  
    <title>zero.data &#8212; Zero 0.0.3.dev10 documentation</title>
    <link rel="stylesheet" href="../../_static/material.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=white data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#_modules/zero/data" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../../index.html" title="Zero 0.0.3.dev10 documentation"
           class="md-header-nav__button md-logo">
          
            <i class="md-icon">&#127968;</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Zero</span>
          <span class="md-header-nav__topic"> zero.data </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../../search.html" method="GET" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/Yura52/zero" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Zero
  </div>
</a>
          </div>
        </div>
      
      
  
  <div class="md-flex__cell md-flex__cell--shrink dropdown">
    <button class="dropdownbutton">Versions</button>
    <div class="dropdown-content md-hero">
          <a title="Development" href="">Development</a>
      
    </div>
  </div>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
          <li class="md-tabs__item"><a href="../index.html" class="md-tabs__link">Module code</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../../index.html" title="Zero 0.0.3.dev10 documentation" class="md-nav__button md-logo">
      
        <i class="md-icon">&#127968;</i>
      
    </a>
    <a href="../../index.html"
       title="Zero 0.0.3.dev10 documentation">Zero</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/Yura52/zero" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Zero
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">NOTES</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../learn.html" class="md-nav__link">Learn</a>
      
    
    </li>
    <li class="md-nav__item">
    
      <span class="md-nav__link caption"><span class="caption-text">API REFERENCE</span></span>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../reference/zero.html" class="md-nav__link">zero</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../reference/data.html" class="md-nav__link">zero.data</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../reference/hardware.html" class="md-nav__link">zero.hardware</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../../reference/random.html" class="md-nav__link">zero.random</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
  <ul class="md-nav__list" data-md-scrollfix="">
    

<li id="searchbox" class="md-nav__item"></li>

  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <h1 id="modules-zero-data--page-root">Source code for zero.data</h1><div class="highlight"><pre>
<span></span><span class="sd">"""Missing batteries from `torch.utils.data`."""</span>

<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">Iterable</span><span class="p">,</span>
    <span class="n">Iterator</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">TypeVar</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">TensorDataset</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s1">'T'</span><span class="p">)</span>


<div class="viewcode-block" id="Enumerate"><a class="viewcode-back" href="../../reference/api/zero.data.Enumerate.html#zero.data.Enumerate">[docs]</a><span class="k">class</span> <span class="nc">Enumerate</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">"""Make dataset return both indices and items.</span>

<span class="sd">    .. rubric:: Tutorial</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        from torch.utils.data import DataLoader, TensorDataset</span>
<span class="sd">        X, y = torch.randn(9, 2), torch.randn(9)</span>
<span class="sd">        dataset = TensorDataset(X, y)</span>
<span class="sd">        for batch_idx, batch in DataLoader(Enumerate(dataset), batch_size=3):</span>
<span class="sd">            print(batch_idx)</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        tensor([0, 1, 2])</span>
<span class="sd">        tensor([3, 4, 5])</span>
<span class="sd">        tensor([6, 7, 8])</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="Enumerate.__init__"><a class="viewcode-back" href="../../reference/api/api/zero.data.Enumerate.__init__.html#zero.data.Enumerate.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Initialize self.</span>

<span class="sd">        Args:</span>
<span class="sd">            dataset</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span> <span class="o">=</span> <span class="n">dataset</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
        <span class="sd">"""Access the underlying dataset.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The dataset.</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span>

<div class="viewcode-block" id="Enumerate.__len__"><a class="viewcode-back" href="../../reference/api/api/zero.data.Enumerate.__len__.html#zero.data.Enumerate.__len__">[docs]</a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Get the length of the underlying dataset."""</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">)</span></div>

<div class="viewcode-block" id="Enumerate.__getitem__"><a class="viewcode-back" href="../../reference/api/api/zero.data.Enumerate.__getitem__.html#zero.data.Enumerate.__getitem__">[docs]</a>    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sd">"""Return index and the corresponding item from the underlying dataset.</span>

<span class="sd">        Args:</span>
<span class="sd">            index</span>
<span class="sd">        Returns:</span>
<span class="sd">            (index, item)</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="n">index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span></div></div>


<div class="viewcode-block" id="FnDataset"><a class="viewcode-back" href="../../reference/api/zero.data.FnDataset.html#zero.data.FnDataset">[docs]</a><span class="k">class</span> <span class="nc">FnDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">"""A thin wrapper around a loader function and its arguments.</span>

<span class="sd">    `FnDataset` allows to avoid implementing Dataset-classes (well, at least in simple</span>
<span class="sd">    cases). Below you can find the full tutorial and typical use cases, but here is a</span>
<span class="sd">    quick example:</span>

<span class="sd">    Without `FnDataset`::</span>

<span class="sd">        class ImagesList(Dataset):</span>
<span class="sd">            def __init__(self, filenames, transform):</span>
<span class="sd">                self.filenames = filenames</span>
<span class="sd">                self.transform = transform</span>

<span class="sd">            def __len__(self):</span>
<span class="sd">                return len(self.filenames)</span>

<span class="sd">            def __getitem__(self, index):</span>
<span class="sd">                return self.transform(Image.open(self.filenames[index]))</span>

<span class="sd">        dataset = ImagesList(filenames, transform)</span>

<span class="sd">    With `FnDataset`::</span>

<span class="sd">        dataset = FnDataset(Image.open, filenames, transform)</span>

<span class="sd">    .. rubric:: Tutorial</span>

<span class="sd">    With vanilla PyTorch, in order to create a dataset you have to inherit from</span>
<span class="sd">    `torch.utils.data.Dataset` and implement three methods:</span>

<span class="sd">    - :code:`__init__`</span>
<span class="sd">    - :code:`__len__`</span>
<span class="sd">    - :code:`__getitem__`</span>

<span class="sd">    With `FnDataset` the only thing you *may need* to implement is the :code:`fn`</span>
<span class="sd">    argument that will power :code:`__getitem__`. The easiest way to learn</span>
<span class="sd">    `FnDataset` is to go through examples below.</span>

<span class="sd">    A list of images::</span>

<span class="sd">        dataset = FnDataset(Image.open, filenames)</span>
<span class="sd">        # dataset[i] returns Image.open(filenames[i])</span>

<span class="sd">    A list of images that are cached after the first load::</span>

<span class="sd">        from functools import lru_cache</span>
<span class="sd">        dataset = FnDataset(lru_cache(None)(Image.open), filenames)</span>

<span class="sd">    `pathlib.Path` is very useful when you want to create a dataset that reads from</span>
<span class="sd">    files. For example::</span>

<span class="sd">        images_dir = Path(...)</span>
<span class="sd">        dataset = FnDataset(Image.open, images_dir.iterdir())</span>

<span class="sd">    If there are many files, but you need only those with specific extensions, use</span>
<span class="sd">    `pathlib.Path.glob`::</span>

<span class="sd">        dataset = FnDataset(Image.open, images_dir.glob(*.png))</span>

<span class="sd">    If there are many files in many subfolders, but you need only those with specific</span>
<span class="sd">    extensions and that satisfy some condition, use `pathlib.Path.rglob`::</span>

<span class="sd">        dataset = FnDataset(</span>
<span class="sd">            Image.open, (x for x in images_dir.rglob(*.png) if condition(x))</span>
<span class="sd">        )</span>

<span class="sd">    A segmentation dataset::</span>

<span class="sd">        image_filenames = ...</span>
<span class="sd">        gt_filenames = ...</span>

<span class="sd">        def get(i):</span>
<span class="sd">            return Image.open(image_filenames[i]), Image.open(gt_filenames[i])</span>

<span class="sd">        dataset = FnDataset(get, len(image_filenames))</span>

<span class="sd">    A dummy dataset that demonstrates that `FnDataset` is a very general thing:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        def f(x):</span>
<span class="sd">            return x * 10</span>

<span class="sd">        def g(x):</span>
<span class="sd">            return x * 2</span>

<span class="sd">        dataset = FnDataset(f, 3, g)</span>
<span class="sd">        # dataset[i] returns g(f(i))</span>
<span class="sd">        assert len(dataset) == 3</span>
<span class="sd">        assert dataset[0] == 0</span>
<span class="sd">        assert dataset[1] == 20</span>
<span class="sd">        assert dataset[2] == 40</span>

<span class="sd">    """</span>

<div class="viewcode-block" id="FnDataset.__init__"><a class="viewcode-back" href="../../reference/api/api/zero.data.FnDataset.__init__.html#zero.data.FnDataset.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">T</span><span class="p">],</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">],</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="n">T</span><span class="p">],</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Initialize self.</span>

<span class="sd">        Args:</span>
<span class="sd">            fn: the function that produces values based on arguments from :code:`args`</span>
<span class="sd">            args: arguments for :code:`fn`. If an iterable, but not a list, then is</span>
<span class="sd">                casted to a list. If an integer, then the behavior is the same as for</span>
<span class="sd">                :code:`list(range(args))`. The size of :code:`args` defines the return</span>
<span class="sd">                value for `FnDataset.__len__`.</span>
<span class="sd">            transform: if presented, is applied to the return value of `fn` in</span>
<span class="sd">                `FnDataset.__getitem__`</span>

<span class="sd">        Examples:</span>
<span class="sd">            .. code-block::</span>

<span class="sd">                import PIL.Image as Image</span>
<span class="sd">                import torchvision.transforms as T</span>

<span class="sd">                dataset = FnDataset(Image.open, filenames, T.ToTensor())</span>
<span class="sd">        """</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span> <span class="o">=</span> <span class="n">fn</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">args</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="n">transform</span></div>

<div class="viewcode-block" id="FnDataset.__len__"><a class="viewcode-back" href="../../reference/api/api/zero.data.FnDataset.__len__.html#zero.data.FnDataset.__len__">[docs]</a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Get the dataset size.</span>

<span class="sd">        See `FnDataset` for details.</span>

<span class="sd">        Returns:</span>
<span class="sd">            size</span>
<span class="sd">        """</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args</span></div>

<div class="viewcode-block" id="FnDataset.__getitem__"><a class="viewcode-back" href="../../reference/api/api/zero.data.FnDataset.__getitem__.html#zero.data.FnDataset.__getitem__">[docs]</a>    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">"""Get value by index.</span>

<span class="sd">        See `FnDataset` for details.</span>

<span class="sd">        Args:</span>
<span class="sd">            index</span>
<span class="sd">        Returns:</span>
<span class="sd">            value</span>
<span class="sd">        Raises:</span>
<span class="sd">            IndexError: if :code:`index &gt;= len(self)`</span>
<span class="sd">        """</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_args</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">index</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Index </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s1"> is out of range'</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div></div>


<span class="k">class</span> <span class="nc">_IndicesDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">i</span>


<div class="viewcode-block" id="IndexLoader"><a class="viewcode-back" href="../../reference/api/zero.data.IndexLoader.html#zero.data.IndexLoader">[docs]</a><span class="k">class</span> <span class="nc">IndexLoader</span><span class="p">:</span>
    <span class="sd">"""Like `~torch.utils.data.DataLoader`, but over indices instead of data.</span>

<span class="sd">    **The shuffling logic is delegated to the native PyTorch DataLoader**, i.e. no</span>
<span class="sd">    custom logic is performed under the hood. The data loader which actually generates</span>
<span class="sd">    indices is available as `IndexLoader.loader`.</span>

<span class="sd">    Examples:</span>
<span class="sd">        Usage for training:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            train_loader = IndexLoader(len(train_dataset), batch_size, shuffle=True)</span>
<span class="sd">            for epoch in epochs:</span>
<span class="sd">                for batch_idx in train_loader:</span>
<span class="sd">                    ...</span>

<span class="sd">        Other examples:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            dataset_size = 10  # len(dataset)</span>
<span class="sd">            for batch_idx in IndexLoader(dataset_size, batch_size=3):</span>
<span class="sd">                print(batch_idx)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            tensor([0, 1, 2])</span>
<span class="sd">            tensor([3, 4, 5])</span>
<span class="sd">            tensor([6, 7, 8])</span>
<span class="sd">            tensor([9])</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            dataset_size = 10  # len(dataset)</span>
<span class="sd">            for batch_idx in IndexLoader(dataset_size, 3, drop_last=True):</span>
<span class="sd">                print(batch_idx)</span>

<span class="sd">        .. testoutput::</span>

<span class="sd">            tensor([0, 1, 2])</span>
<span class="sd">            tensor([3, 4, 5])</span>
<span class="sd">            tensor([6, 7, 8])</span>

<span class="sd">    See also:</span>
<span class="sd">        `zero.iter_batches`</span>
<span class="sd">    """</span>

<div class="viewcode-block" id="IndexLoader.__init__"><a class="viewcode-back" href="../../reference/api/api/zero.data.IndexLoader.__init__.html#zero.data.IndexLoader.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'cpu'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">"""Initialize self.</span>

<span class="sd">        Args:</span>
<span class="sd">            size: the number of items (for example, :code:`len(dataset)`)</span>
<span class="sd">            *args: positional arguments for `torch.utils.data.DataLoader`</span>
<span class="sd">            device: if not CPU, then all indices are materialized and moved to the</span>
<span class="sd">                device at the beginning of every loop. It can be useful when the indices</span>
<span class="sd">                are applied to non-CPU data (e.g. CUDA-tensors) and moving data between</span>
<span class="sd">                devices takes non-negligable time (which can happen in the case of</span>
<span class="sd">                simple and fast models like MLPs).</span>
<span class="sd">            **kwargs: keyword arguments for `torch.utils.data.DataLoader`</span>
<span class="sd">        Raises:</span>
<span class="sd">            AssertionError: if size is not positive</span>
<span class="sd">        """</span>
        <span class="k">assert</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">args</span> <span class="k">else</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'batch_size'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">_IndicesDataset</span><span class="p">(</span><span class="n">size</span><span class="p">),</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">)):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_device</span> <span class="o">=</span> <span class="n">device</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">loader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
        <span class="sd">"""The underlying DataLoader."""</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loader</span>

<div class="viewcode-block" id="IndexLoader.__len__"><a class="viewcode-back" href="../../reference/api/api/zero.data.IndexLoader.__len__.html#zero.data.IndexLoader.__len__">[docs]</a>    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sd">"""Get the size of the underlying DataLoader."""</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">)</span></div>

<div class="viewcode-block" id="IndexLoader.__iter__"><a class="viewcode-back" href="../../reference/api/api/zero.data.IndexLoader.__iter__.html#zero.data.IndexLoader.__iter__">[docs]</a>    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_loader</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">'cpu'</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loader</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_device</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_size</span><span class="p">)</span>
        <span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_is_namedtuple</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span> <span class="k">for</span> <span class="n">attr</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'_make'</span><span class="p">,</span> <span class="s1">'_asdict'</span><span class="p">,</span> <span class="s1">'_replace'</span><span class="p">,</span> <span class="s1">'_fields'</span><span class="p">]</span>
    <span class="p">)</span>


<div class="viewcode-block" id="iter_batches"><a class="viewcode-back" href="../../reference/api/zero.iter_batches.html#zero.data.iter_batches">[docs]</a><span class="k">def</span> <span class="nf">iter_batches</span><span class="p">(</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">TensorDataset</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">:</span>
    <span class="sd">"""*Efficiently* iterate over data (tensor, tuple of tensors, dict of tensors etc.)</span>
<span class="sd">    in a batchwise manner.</span>

<span class="sd">    The function is useful when you want to *efficiently* iterate **once** over</span>
<span class="sd">    tensor-based data in a batchwise manner. See examples below for typical use cases.</span>

<span class="sd">    The function is a more efficient alternative to `torch.utils.data.DataLoader` when</span>
<span class="sd">    it comes to in-memory data, because it uses batch-based indexing instead of</span>
<span class="sd">    item-based indexing (DataLoader's behavior). **The shuffling logic is delegated to</span>
<span class="sd">    the native PyTorch DataLoader**, i.e. no custom logic is performed under the hood.</span>

<span class="sd">    Args:</span>
<span class="sd">        data:</span>
<span class="sd">        *args: positional arguments for `IndexLoader`</span>
<span class="sd">        **kwargs: keyword arguments for `IndexLoader`</span>
<span class="sd">    Returns:</span>
<span class="sd">        Iterator over batches.</span>

<span class="sd">    Warning:</span>
<span class="sd">        Numpy-arrays are not supported because of how they behave when indexed by a</span>
<span class="sd">        torch tensor of the size 1. For details, see</span>
<span class="sd">        `the issue &lt;https://github.com/numpy/numpy/issues/16543&gt;`_</span>

<span class="sd">    Note:</span>
<span class="sd">        If you want to infititely iterate over batches, wrap the function in</span>
<span class="sd">        :code:`while True:`.</span>

<span class="sd">    See also:</span>
<span class="sd">        - `zero.data.IndexLoader`</span>
<span class="sd">        - `concat`</span>

<span class="sd">    Examples:</span>
<span class="sd">        Besides loops over batches, the function can be used in combination with</span>
<span class="sd">        `concat`:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            result = concat(map(fn, iter_batches(dataset_or_tensors_or_whatever, ...)))</span>

<span class="sd">        The function can also be used for training:</span>

<span class="sd">        .. code-block::</span>

<span class="sd">            for epoch in epochs:</span>
<span class="sd">                for batch in iter_batches(data, batch_size, shuffle=True)):</span>
<span class="sd">                    ...</span>
<span class="sd">    """</span>
    <span class="c1"># mypy understands very little about this function</span>
    <span class="k">if</span> <span class="n">_is_namedtuple</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">data</span>
        <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>  <span class="c1"># type: ignore # noqa</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># type: ignore # noqa</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">data</span>
        <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)(</span><span class="n">x</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span>  <span class="c1"># type: ignore # noqa</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># type: ignore # noqa</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">data</span>
        <span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>  <span class="c1"># type: ignore # noqa</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">())))</span>  <span class="c1"># type: ignore # noqa</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="fm">__getitem__</span>
        <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># type: ignore # noqa</span>
    <span class="k">return</span> <span class="nb">map</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">IndexLoader</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span></div>


<div class="viewcode-block" id="concat"><a class="viewcode-back" href="../../reference/api/zero.concat.html#zero.data.concat">[docs]</a><span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="n">iterable</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">T</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="sd">"""Concatenate items (tensors, numpy-arrays, tuples, dicts etc.) along the first</span>
<span class="sd">    dimension.</span>

<span class="sd">    `concat` is a more general version of :code:`torch.cat(..., dim=0)`. It works not</span>
<span class="sd">    only with sequences of tensors, but also with sequences of containers (tuples,</span>
<span class="sd">    dicts etc.) of different types of data (tensors, numpy-arrays, primitive types). See</span>
<span class="sd">    the tutorial and the examples below to understand what the function does.</span>

<span class="sd">    Args:</span>
<span class="sd">        iterable: items **of the same structure** (for example, "an iterable of tensors"</span>
<span class="sd">            OR "an iterable of tuples of tensors where all the tuples are of the same</span>
<span class="sd">            length" OR "an iterable of dicts of tensors and numpy-arrays where all the</span>
<span class="sd">            dicts have the same keys" etc.)</span>
<span class="sd">    Returns:</span>
<span class="sd">        Concatenated items of the iterable.</span>

<span class="sd">    Note:</span>
<span class="sd">        The concatenation algorithm is fully determined by the first item of the</span>
<span class="sd">        iterable. If there are items of different structure, then the function is</span>
<span class="sd">        likely to fail or produce incorrect results, hence the requirement of the</span>
<span class="sd">        same structure for all items of the iterable.</span>

<span class="sd">    Warning:</span>
<span class="sd">        The function starts with conversion of the iterable to a list. Make sure that</span>
<span class="sd">        you have enough memory for such operation, otherwise, memory limit may be</span>
<span class="sd">        exceeded. Note that in most cases manual implementation would involve the same</span>
<span class="sd">        conversion, just keep this in mind when using the function.</span>

<span class="sd">    See also:</span>
<span class="sd">        `iter_batches`</span>

<span class="sd">    .. rubric:: Tutorial</span>

<span class="sd">    For usage examples, scroll further.</span>

<span class="sd">    If you have an iterable that contains/produces batches of some kind (tensors,</span>
<span class="sd">    numpy-arrays, tuples/dictionaries thereof and other not-too-specific content), then</span>
<span class="sd">    use `concat` to concatenate all the items. A prominent case is application of models</span>
<span class="sd">    and functions to batches (e.g. to :code:`DataLoader`)::</span>

<span class="sd">        whole_result = concat(map(model_or_fn, batches))</span>
<span class="sd">        # or</span>
<span class="sd">        whole_result = concat(expression(x) for x in batches)</span>

<span class="sd">    For example::</span>

<span class="sd">        dataset = ...  # PyTorch dataset</span>
<span class="sd">        loader = DataLoader(dataset, batch_size)</span>

<span class="sd">        def step(batch):</span>
<span class="sd">            X, y = batch</span>
<span class="sd">            return model(X), y</span>

<span class="sd">        y_pred, y = concat(map(step, loader))</span>
<span class="sd">        assert len(y_pred) == len(dataset) and len(y) == len(dataset)</span>

<span class="sd">        # or</span>
<span class="sd">        def step(batch):</span>
<span class="sd">            X, y = batch</span>
<span class="sd">            return {'y_pred': model(X), 'y': y}</span>

<span class="sd">        result = concat(map(step, loader))  # no changes</span>
<span class="sd">        assert result['y_pred'] == len(dataset) and len(result['y']) == len(dataset)</span>

<span class="sd">    The function can be used in combination with `iter_batches`. For example, this is</span>
<span class="sd">    how pairwise dot products can be calculated in a batchwise manner if full matrix</span>
<span class="sd">    multiplication does not fit into memory:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        n_objects = 100</span>
<span class="sd">        n_features = 16</span>
<span class="sd">        batch_size = 20</span>
<span class="sd">        data = torch.randn(n_objects, n_features)</span>
<span class="sd">        result = concat(</span>
<span class="sd">            batch.matmul(data.T).to('cpu') for batch in iter_batches(data, batch_size)</span>
<span class="sd">        )</span>
<span class="sd">        assert result.shape == (n_objects, n_objects)</span>

<span class="sd">    Or even like this:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        n_objects = 100</span>
<span class="sd">        n_features = 16</span>
<span class="sd">        batch_size = 20</span>
<span class="sd">        data = torch.randn(n_objects, n_features)</span>
<span class="sd">        result = concat(</span>
<span class="sd">            concat(b.matmul(a.T).to('cpu') for b in iter_batches(data, batch_size)).T</span>
<span class="sd">            for a in iter_batches(data, batch_size)</span>
<span class="sd">        )</span>
<span class="sd">        assert result.shape == (n_objects, n_objects)</span>

<span class="sd">    Examples:</span>
<span class="sd">        How to read the examples:</span>

<span class="sd">        - the mental model for understanding the following examples is "concatenating</span>
<span class="sd">          data for 3 batches of sizes (2, 2, 3)". Note that sizes of batches are</span>
<span class="sd">          allowed to vary, but the structure is always the same</span>
<span class="sd">        - in all examples there is :code:`data` - a list of batches; in fact, it can be</span>
<span class="sd">          any "iterable of batches", including iterators and generators; the list is</span>
<span class="sd">          chosen to simplify the demonstration</span>

<span class="sd">        1-D example:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            result = concat([</span>
<span class="sd">                torch.tensor([0, 1]), torch.tensor([2, 3]), torch.tensor([4, 5, 6])</span>
<span class="sd">            ])</span>
<span class="sd">            assert torch.equal(result, torch.tensor([0, 1, 2, 3, 4, 5, 6]))</span>

<span class="sd">        2-D example:</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            result = concat([</span>
<span class="sd">                torch.tensor([</span>
<span class="sd">                    [0, 0],</span>
<span class="sd">                    [1, 1]</span>
<span class="sd">                ]),</span>
<span class="sd">                torch.tensor([</span>
<span class="sd">                    [2, 2],</span>
<span class="sd">                    [3, 3]</span>
<span class="sd">                ]),</span>
<span class="sd">                torch.tensor([</span>
<span class="sd">                    [4, 4],</span>
<span class="sd">                    [5, 5],</span>
<span class="sd">                    [6, 6],</span>
<span class="sd">                ]),</span>
<span class="sd">            ])</span>
<span class="sd">            assert torch.equal(</span>
<span class="sd">                result,</span>
<span class="sd">                torch.tensor([</span>
<span class="sd">                    [0, 0],</span>
<span class="sd">                    [1, 1],</span>
<span class="sd">                    [2, 2],</span>
<span class="sd">                    [3, 3],</span>
<span class="sd">                    [4, 4],</span>
<span class="sd">                    [5, 5],</span>
<span class="sd">                    [6, 6]</span>
<span class="sd">                ])</span>
<span class="sd">            )</span>

<span class="sd">        N-D example: &lt;the same&gt;.</span>

<span class="sd">        The following examples demonstrate support for different kinds of input data;</span>
<span class="sd">        data is 1-D everywhere just for simplicity (i.e. dimensions can be arbitrary).</span>

<span class="sd">        .. testcode::</span>

<span class="sd">            array = np.array</span>
<span class="sd">            tensor = torch.tensor</span>
<span class="sd">            l = [0, 1, 2, 3, 4, 5, 6]</span>
<span class="sd">            a = array([0, 1, 2, 3, 4, 5, 6])</span>
<span class="sd">            t = tensor([0, 1, 2, 3, 4, 5, 6])</span>

<span class="sd">            data = [[0, 1], [2, 3], [4, 5, 6]]</span>
<span class="sd">            assert concat(data) == l</span>

<span class="sd">            data = [array([0, 1]), array([2, 3]), array([4, 5, 6])]</span>
<span class="sd">            assert np.array_equal(concat(data), a)</span>

<span class="sd">            data = [tensor([0, 1]), tensor([2, 3]), tensor([4, 5, 6])]</span>
<span class="sd">            assert torch.equal(concat(data), t)</span>

<span class="sd">            # If items are not lists, arrays nor tensors, the data is returned in a form</span>
<span class="sd">            # of a list. It makes sense since the list of such items is already</span>
<span class="sd">            # a result for all batches.</span>
<span class="sd">            data = ['three batches, hence three items', 0, 1.0]</span>
<span class="sd">            assert concat(data) == data</span>

<span class="sd">            data = [</span>
<span class="sd">                ([0, 1], array([0, 1]), tensor([0, 1])),</span>
<span class="sd">                ([2, 3], array([2, 3]), tensor([2, 3])),</span>
<span class="sd">                ([4, 5, 6], array([4, 5, 6]), tensor([4, 5, 6])),</span>
<span class="sd">            ]</span>
<span class="sd">            result = concat(data)</span>
<span class="sd">            assert isinstance(result, tuple) and len(result) == 3</span>
<span class="sd">            assert (</span>
<span class="sd">                result[0] == l</span>
<span class="sd">                and np.array_equal(result[1], a)</span>
<span class="sd">                and torch.equal(result[2], t)</span>
<span class="sd">            )</span>

<span class="sd">            data = [</span>
<span class="sd">                {'l': [0, 1], 'a': array([0, 1]), 't': tensor([0, 1])},</span>
<span class="sd">                {'l': [2, 3], 'a': array([2, 3]), 't': tensor([2, 3])},</span>
<span class="sd">                {'l': [4, 5, 6], 'a': array([4, 5, 6]), 't': tensor([4, 5, 6])},</span>
<span class="sd">            ]</span>
<span class="sd">            result = concat(data)</span>
<span class="sd">            assert isinstance(result, dict) and list(result) == ['l', 'a', 't']</span>
<span class="sd">            assert (</span>
<span class="sd">                result['l'] == l</span>
<span class="sd">                and np.array_equal(result['a'], a)</span>
<span class="sd">                and torch.equal(result['t'], t)</span>
<span class="sd">            )</span>
<span class="sd">    """</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">iterable</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">data</span><span class="p">,</span> <span class="s1">'iterable must be non-empty'</span>

    <span class="k">def</span> <span class="nf">concat_fn</span><span class="p">(</span><span class="n">sequence</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sequence</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">sequence</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">(</span><span class="n">sequence</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="k">else</span> <span class="n">sequence</span>
        <span class="p">)</span>

    <span class="n">first</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="nb">type</span><span class="p">(</span><span class="n">first</span><span class="p">)</span><span class="o">.</span><span class="n">_make</span><span class="p">(</span><span class="n">concat_fn</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">first</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">_is_namedtuple</span><span class="p">(</span><span class="n">first</span><span class="p">)</span>
        <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">first</span><span class="p">)(</span><span class="n">concat_fn</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">first</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span>
        <span class="k">else</span> <span class="nb">type</span><span class="p">(</span><span class="n">first</span><span class="p">)((</span><span class="n">key</span><span class="p">,</span> <span class="n">concat_fn</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">first</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span>
        <span class="k">else</span> <span class="n">concat_fn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="collate"><a class="viewcode-back" href="../../reference/api/zero.collate.html#zero.data.collate">[docs]</a><span class="k">def</span> <span class="nf">collate</span><span class="p">(</span><span class="n">iterable</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">T</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">"""Almost an alias for :code:`torch.utils.data.dataloader.default_collate`.</span>

<span class="sd">    Namely, the input is allowed to be any kind of iterable, not only a list. Firstly,</span>
<span class="sd">    if it is not a list, it is transformed to a list. Then, the list is passed to the</span>
<span class="sd">    original function and the result is returned as is.</span>
<span class="sd">    """</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">iterable</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>
    <span class="c1"># &gt; Module has no attribute "default_collate"</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataloader</span><span class="o">.</span><span class="n">default_collate</span><span class="p">(</span><span class="n">iterable</span><span class="p">)</span>  <span class="c1"># type: ignore</span></div>
</pre></div>

          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">

      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright 2020, Yura52.
              
          </div>
            Created using
            <a href="http://www.sphinx-doc.org/">Sphinx</a> 3.1.2.
             and
            <a href="https://github.com/bashtage/sphinx-material/">Material for
              Sphinx</a>
        </div>
      </div>
    </div>
  </footer>
  <script src="../../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>